{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qch5CoZa4vZ8",
        "outputId": "a9a4f016-44ff-40cc-e6d6-a45cbc75e8b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.14.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Collecting rouge-score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft) (2.6.0+cu124)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft) (1.5.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.17.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.13.0->peft)\n",
            "\u001b[33m  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /packages/67/42/f4f60238e8194a3106d06a058d494b18e006c10bb2b915655bd9f6ea4cb1/nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata\u001b[0m\u001b[33m\n",
            "\u001b[0m  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.13.0->peft)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
            "Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m84.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: rouge-score\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=40bb35b2ae9f0d2f71807006f0321d0f80e7761a3012b17f8e4817925ee381bf\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
            "Successfully built rouge-score\n",
            "Installing collected packages: xxhash, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, fsspec, dill, rouge-score, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, nvidia-cusolver-cu12, datasets, evaluate\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.5.0 dill-0.3.8 evaluate-0.4.3 fsspec-2024.12.0 multiprocess-0.70.16 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 rouge-score-0.1.2 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets evaluate peft nltk rouge-score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Environment setup and imports"
      ],
      "metadata": {
        "id": "fuCHBIar6AWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    T5ForConditionalGeneration,\n",
        "    T5Tokenizer,\n",
        "    Seq2SeqTrainingArguments,  # Note: change to Seq2SeqTrainingArguments\n",
        "    Seq2SeqTrainer,\n",
        "    DataCollatorForSeq2Seq\n",
        ")\n",
        "from peft import get_peft_model, LoraConfig, TaskType\n",
        "import evaluate\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Set up environment\n",
        "print(\"Setting up environment...\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "SEED = 42\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQ7g7sZr6Aol",
        "outputId": "a8fff0fa-c130-48f6-d182-dea50c37edec"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up environment...\n",
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Load dataset\n"
      ],
      "metadata": {
        "id": "R5FlhT1p6Fo6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a small sample from CNN/DailyMail\n",
        "print(\"Loading small sample from CNN/DailyMail dataset...\")\n",
        "dataset = load_dataset(\"abisee/cnn_dailymail\", \"3.0.0\")\n",
        "\n",
        "# Create small samples for POC\n",
        "SAMPLE_SIZE = 15\n",
        "train_dataset = dataset[\"train\"].select(range(SAMPLE_SIZE))\n",
        "val_dataset = dataset[\"validation\"].select(range(5))\n",
        "test_dataset = dataset[\"test\"].select(range(5))\n",
        "\n",
        "print(f\"Dataset samples loaded: {len(train_dataset)} train, {len(val_dataset)} validation, {len(test_dataset)} test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMK8Oelw6F6a",
        "outputId": "5fbeefaf-a24c-455c-f7d0-623f895066d2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading small sample from CNN/DailyMail dataset...\n",
            "Dataset samples loaded: 15 train, 5 validation, 5 test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocess data"
      ],
      "metadata": {
        "id": "ASBHah7F6La_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing function\n",
        "def preprocess_example(example):\n",
        "    \"\"\"Clean text by removing extra spaces and fixing punctuation\"\"\"\n",
        "    article = ' '.join(example[\"article\"].split())\n",
        "    summary = ' '.join(example[\"highlights\"].split())\n",
        "\n",
        "    # Fix spacing around punctuation\n",
        "    for punct in ['.', ',', '!', '?', ';', ':']:\n",
        "        article = article.replace(f\" {punct}\", punct)\n",
        "        summary = summary.replace(f\" {punct}\", punct)\n",
        "\n",
        "    return {\n",
        "        \"article\": article.strip(),\n",
        "        \"summary\": summary.strip(),\n",
        "        \"id\": example[\"id\"]\n",
        "    }\n",
        "\n",
        "# Apply preprocessing\n",
        "print(\"Preprocessing data...\")\n",
        "train_dataset = train_dataset.map(preprocess_example)\n",
        "val_dataset = val_dataset.map(preprocess_example)\n",
        "test_dataset = test_dataset.map(preprocess_example)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMhkCDCb6L6d",
        "outputId": "29fa3495-0b0f-4dfe-8f87-9eb861bfaa8b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load model and setup LoRA"
      ],
      "metadata": {
        "id": "NiI73e-26QrL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model and tokenizer\n",
        "print(\"Loading model and tokenizer...\")\n",
        "MODEL_NAME = \"t5-small\"  # Smaller model (60M parameters) good for beginners\n",
        "tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)\n",
        "base_model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME)\n",
        "\n",
        "# Setup LoRA for parameter-efficient fine-tuning\n",
        "print(\"Setting up LoRA for parameter-efficient fine-tuning...\")\n",
        "peft_config = LoraConfig(\n",
        "    task_type=TaskType.SEQ_2_SEQ_LM,\n",
        "    r=8,                        # Rank of low-rank matrices\n",
        "    lora_alpha=32,              # Parameter scaling\n",
        "    lora_dropout=0.1,\n",
        "    target_modules=[\"q\", \"v\"],  # Only fine-tune query and value projection matrices\n",
        ")\n",
        "\n",
        "# Apply LoRA to model\n",
        "model = get_peft_model(base_model, peft_config)\n",
        "print(f\"Trainable parameters: {model.print_trainable_parameters()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w90nxW5v6RJo",
        "outputId": "0b01c298-9e11-4a73-b175-763dd5bc09d6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model and tokenizer...\n",
            "Setting up LoRA for parameter-efficient fine-tuning...\n",
            "trainable params: 294,912 || all params: 60,801,536 || trainable%: 0.4850\n",
            "Trainable parameters: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenize datasets"
      ],
      "metadata": {
        "id": "Bs741cl_6YKX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization function\n",
        "print(\"Tokenizing datasets...\")\n",
        "PREFIX = \"summarize: \"  # T5 requires task prefix\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    # Prepare inputs with prefix\n",
        "    inputs = [PREFIX + doc for doc in examples[\"article\"]]\n",
        "\n",
        "    # Tokenize inputs (articles)\n",
        "    model_inputs = tokenizer(\n",
        "        inputs,\n",
        "        max_length=512,         # Limit input length\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "    )\n",
        "\n",
        "    # Tokenize targets (summaries)\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(\n",
        "            examples[\"summary\"],\n",
        "            max_length=128,     # Limit summary length\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "        )\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "\n",
        "    # Replace padding token id's with -100 in labels for loss calculation\n",
        "    model_inputs[\"labels\"] = [\n",
        "        [-100 if token == tokenizer.pad_token_id else token for token in label]\n",
        "        for label in model_inputs[\"labels\"]\n",
        "    ]\n",
        "\n",
        "    return model_inputs\n",
        "\n",
        "# Apply tokenization\n",
        "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
        "tokenized_val = val_dataset.map(tokenize_function, batched=True)\n",
        "tokenized_test = test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Set format for PyTorch\n",
        "tokenized_train.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "tokenized_val.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "tokenized_test.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Im1ThjAE6YsN",
        "outputId": "434f1d71-496d-43a4-a456-41bd9539c95e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizing datasets...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup training arguments and trainer"
      ],
      "metadata": {
        "id": "eyatGABp6iMz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "print(\"Transformers version:\", transformers.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnMDcIOL627a",
        "outputId": "7fb9da13-b747-48e0-bb56-6bbcfd399c74"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformers version: 4.51.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Minimal training args compatible with transformers 4.51.3\n",
        "# training_args = Seq2SeqTrainingArguments(\n",
        "#     output_dir=\"./results_t5_cnn_lora\",\n",
        "#     per_device_train_batch_size=2,\n",
        "#     per_device_eval_batch_size=2,\n",
        "#     learning_rate=1e-3,\n",
        "#     num_train_epochs=3,\n",
        "#     predict_with_generate=True,\n",
        "#     remove_unused_columns=False\n",
        "# )\n",
        "\n",
        "# Updated training arguments without wandb\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./results_t5_cnn_lora\",\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=2,\n",
        "    learning_rate=1e-3,\n",
        "    num_train_epochs=3,\n",
        "    predict_with_generate=True,\n",
        "    remove_unused_columns=False,\n",
        "    report_to=None  # This disables wandb and other reporting\n",
        ")\n",
        "\n",
        "# Setup evaluation metrics\n",
        "print(\"Setting up evaluation metrics...\")\n",
        "rouge = evaluate.load(\"rouge\")\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    preds, labels = eval_preds\n",
        "\n",
        "    # Decode predictions\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "\n",
        "    # Replace -100 with pad token id\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # ROUGE expects a newline after each sentence\n",
        "    decoded_preds = [\"\\n\".join(pred.split()) for pred in decoded_preds]\n",
        "    decoded_labels = [\"\\n\".join(label.split()) for label in decoded_labels]\n",
        "\n",
        "    # Compute ROUGE scores\n",
        "    result = rouge.compute(\n",
        "        predictions=decoded_preds,\n",
        "        references=decoded_labels,\n",
        "        use_stemmer=True\n",
        "    )\n",
        "\n",
        "    # Extract ROUGE f1 scores\n",
        "    result = {key: value * 100 for key, value in result.items()}\n",
        "\n",
        "    # Add mean generated length\n",
        "    prediction_lens = [len(pred.split()) for pred in decoded_preds]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "\n",
        "    return result\n",
        "\n",
        "# Setup data collator\n",
        "data_collator = DataCollatorForSeq2Seq(\n",
        "    tokenizer=tokenizer,\n",
        "    model=model,\n",
        "    padding=True,\n",
        ")\n",
        "\n",
        "# Initialize trainer\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_val,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJ-tgPLX6-UC",
        "outputId": "d2db2d5b-73c6-4979-a0f0-938d56324d15"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up evaluation metrics...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-7cb0474b47c9>:66: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Seq2SeqTrainer(\n",
            "No label_names provided for model class `PeftModelForSeq2SeqLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "HToAEqRN7dk2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tune the model\n",
        "print(\"Starting fine-tuning...\")\n",
        "trainer.train()\n",
        "\n",
        "# Evaluate on test set\n",
        "print(\"Evaluating fine-tuned model...\")\n",
        "test_results = trainer.evaluate(tokenized_test)\n",
        "print(\"Test results:\", test_results)\n",
        "\n",
        "# Save the fine-tuned model\n",
        "print(\"Saving fine-tuned model...\")\n",
        "trainer.save_model(\"./final_model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "id": "AhxLAeza7d3Q",
        "outputId": "a22015ff-fdfb-4f4a-8447-6369f9a76925"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting fine-tuning...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mveerabomma-s\u001b[0m (\u001b[33mveerabomma-s-northeastern-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250423_232156-yk4vaowm</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/veerabomma-s-northeastern-university/huggingface/runs/yk4vaowm' target=\"_blank\">./results_t5_cnn_lora</a></strong> to <a href='https://wandb.ai/veerabomma-s-northeastern-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/veerabomma-s-northeastern-university/huggingface' target=\"_blank\">https://wandb.ai/veerabomma-s-northeastern-university/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/veerabomma-s-northeastern-university/huggingface/runs/yk4vaowm' target=\"_blank\">https://wandb.ai/veerabomma-s-northeastern-university/huggingface/runs/yk4vaowm</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/data/data_collator.py:741: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n",
            "  batch[\"labels\"] = torch.tensor(batch[\"labels\"], dtype=torch.int64)\n",
            "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [24/24 01:28, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating fine-tuned model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/3 00:07]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test results: {'eval_loss': 1.8993135690689087, 'eval_rouge1': 27.966507177033495, 'eval_rouge2': 8.907626994583516, 'eval_rougeL': 21.94178628389155, 'eval_rougeLsum': 27.983253588516742, 'eval_gen_len': 13.4, 'eval_runtime': 11.8942, 'eval_samples_per_second': 0.42, 'eval_steps_per_second': 0.252, 'epoch': 3.0}\n",
            "Saving fine-tuned model...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test inference on examples\n",
        "print(\"\\nGenerating summaries for test examples...\")\n",
        "model.eval()\n",
        "for i, example in enumerate(test_dataset):\n",
        "    article = example[\"article\"]\n",
        "    reference_summary = example[\"summary\"]\n",
        "\n",
        "    # Prepare input for generation\n",
        "    input_text = PREFIX + article\n",
        "    input_ids = tokenizer(input_text, return_tensors=\"pt\", max_length=512, truncation=True).input_ids.to(device)\n",
        "\n",
        "    # Generate summary\n",
        "    outputs = model.generate(\n",
        "        input_ids=input_ids,\n",
        "        max_length=128,\n",
        "        min_length=30,\n",
        "        num_beams=4,\n",
        "        length_penalty=2.0,\n",
        "        early_stopping=True,\n",
        "    )\n",
        "\n",
        "    # Decode summary\n",
        "    predicted_summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    print(f\"\\nExample {i+1}:\")\n",
        "    print(f\"Article (first 150 chars): {article[:150]}...\")\n",
        "    print(f\"Reference summary: {reference_summary}\")\n",
        "    print(f\"Predicted summary: {predicted_summary}\")\n",
        "\n",
        "print(\"\\nFine-tuning completed successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OYr95w6AKdb",
        "outputId": "9f3a0fad-8110-4864-dfb1-c2e44ce3323e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generating summaries for test examples...\n",
            "\n",
            "Example 1:\n",
            "Article (first 150 chars): (CNN)The Palestinian Authority officially became the 123rd member of the International Criminal Court on Wednesday, a step that gives the court jurisd...\n",
            "Reference summary: Membership gives the ICC jurisdiction over alleged crimes committed in Palestinian territories since last June. Israel and the United States opposed the move, which could open the door to war crimes investigations against Israelis.\n",
            "Predicted summary: the Palestinian Authority officially became the 123rd member of the International Criminal Court on Wednesday. the Palestinians signed the ICC's founding Rome Statute in January. Israel and the United States opposed the Palestinians' efforts to join the body.\n",
            "\n",
            "Example 2:\n",
            "Article (first 150 chars): (CNN)Never mind cats having nine lives. A stray pooch in Washington State has used up at least three of her own after being hit by a car, apparently w...\n",
            "Reference summary: Theia, a bully breed mix, was apparently hit by a car, whacked with a hammer and buried in a field. \"She's a true miracle dog and she deserves a good life,\" says Sara Mellado, who is looking for a home for Theia.\n",
            "Predicted summary: Theia, a friendly white-and-black bully breed mix, has been receiving care at the Veterinary Teaching Hospital. the dog staggered to a nearby farm, dirt-covered and emaciated, where she was found by a worker. Theia suffered a dislocated jaw, leg injuries and a caved-in sinus cavity.\n",
            "\n",
            "Example 3:\n",
            "Article (first 150 chars): (CNN)If you've been following the news lately, there are certain things you doubtless know about Mohammad Javad Zarif. He is, of course, the Iranian f...\n",
            "Reference summary: Mohammad Javad Zarif has spent more time with John Kerry than any other foreign minister. He once participated in a takeover of the Iranian Consulate in San Francisco. The Iranian foreign minister tweets in English.\n",
            "Predicted summary: \"Long live Zarif,\" crowds chanted as his car rolled slowly down the packed street. Zarif tweeted \"Happy Rosh Hashanah,\" referring to the Jewish New Year. Zarif was nominated to be foreign minister by Ahmadinejad's successor.\n",
            "\n",
            "Example 4:\n",
            "Article (first 150 chars): (CNN)Five Americans who were monitored for three weeks at an Omaha, Nebraska, hospital after being exposed to Ebola in West Africa have been released,...\n",
            "Reference summary: 17 Americans were exposed to the Ebola virus while in Sierra Leone in March. Another person was diagnosed with the disease and taken to hospital in Maryland. National Institutes of Health says the patient is in fair condition after weeks of treatment.\n",
            "Predicted summary: five americans were monitored for three weeks at Omaha, Nebraska, hospital after being exposed to Ebola in West Africa. one of the five had a heart-related issue on Saturday and has been discharged but hasn't left the area. they are clinicians for Partners in Health, a Boston-based aid group.\n",
            "\n",
            "Example 5:\n",
            "Article (first 150 chars): (CNN)A Duke student has admitted to hanging a noose made of rope from a tree near a student union, university officials said Thursday. The prestigious...\n",
            "Reference summary: Student is no longer on Duke University campus and will face disciplinary review. School officials identified student during investigation and the person admitted to hanging the noose, Duke says. The noose, made of rope, was discovered on campus about 2 a.m.\n",
            "Predicted summary: Duke student admitted to hanging a noose from a tree near a student union. the student was identified during an investigation by campus police and the office of student affairs. the incident is one of several recent racist events to affect college students.\n",
            "\n",
            "Fine-tuning completed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Additional Evaluation Metrics"
      ],
      "metadata": {
        "id": "KiVi2350A7JA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bert_score"
      ],
      "metadata": {
        "id": "q8k7vpJIBrxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "\n",
        "# BERTScore - semantic similarity (higher is better)\n",
        "bertscore = evaluate.load(\"bertscore\")\n",
        "def calculate_bertscore(predictions, references):\n",
        "    results = bertscore.compute(\n",
        "        predictions=predictions,\n",
        "        references=references,\n",
        "        lang=\"en\"\n",
        "    )\n",
        "    return {\"precision\": np.mean(results[\"precision\"]),\n",
        "            \"recall\": np.mean(results[\"recall\"]),\n",
        "            \"f1\": np.mean(results[\"f1\"])}\n",
        "\n",
        "# METEOR - human correlation (higher is better)\n",
        "meteor = evaluate.load(\"meteor\")\n",
        "def calculate_meteor(predictions, references):\n",
        "    return meteor.compute(predictions=predictions, references=references)\n",
        "\n",
        "# Apply these metrics to your test results\n",
        "preds = []\n",
        "refs = []\n",
        "for i, example in enumerate(test_dataset):\n",
        "    # Generate prediction for this example\n",
        "    input_text = PREFIX + example[\"article\"]\n",
        "    input_ids = tokenizer(input_text, return_tensors=\"pt\", max_length=512, truncation=True).input_ids.to(device)\n",
        "    outputs = model.generate(input_ids=input_ids, max_length=128)\n",
        "    prediction = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    preds.append(prediction)\n",
        "    refs.append(example[\"summary\"])\n",
        "\n",
        "print(\"\\nAdditional Metrics:\")\n",
        "print(\"BERTScore:\", calculate_bertscore(preds, refs))\n",
        "print(\"METEOR:\", calculate_meteor(preds, refs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKTJuhM3A7mc",
        "outputId": "9c81c4e9-989d-4e01-af1b-66554e6932b1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Additional Metrics:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERTScore: {'precision': np.float64(0.8760390162467957), 'recall': np.float64(0.8802922368049622), 'f1': np.float64(0.8781285166740418)}\n",
            "METEOR: {'meteor': np.float64(0.25584445671597134)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare with Baseline Models\n",
        "The most compelling comparison is with baseline models:"
      ],
      "metadata": {
        "id": "hpJXEUMuBzik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First, get the actual keys in your test_results\n",
        "print(\"Available keys in test_results:\")\n",
        "for key in test_results.keys():\n",
        "    print(f\"- {key}\")\n",
        "\n",
        "# Modified comparison function\n",
        "def evaluate_and_compare():\n",
        "    # Load untuned T5 model\n",
        "    print(\"Loading baseline model...\")\n",
        "    baseline_model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
        "    baseline_model.to(device)\n",
        "\n",
        "    # Prepare test examples\n",
        "    preds = []\n",
        "    baseline_preds = []\n",
        "    refs = []\n",
        "\n",
        "    print(\"Generating predictions...\")\n",
        "    for i, example in enumerate(test_dataset):\n",
        "        # Get article and reference summary\n",
        "        article = example[\"article\"]\n",
        "        reference = example[\"summary\"]\n",
        "        refs.append(reference)\n",
        "\n",
        "        # Prepare input\n",
        "        input_text = PREFIX + article\n",
        "        input_ids = tokenizer(input_text, return_tensors=\"pt\", max_length=512, truncation=True).input_ids.to(device)\n",
        "\n",
        "        # Generate with fine-tuned model\n",
        "        outputs = model.generate(input_ids=input_ids, max_length=128)\n",
        "        prediction = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        preds.append(prediction)\n",
        "\n",
        "        # Generate with baseline model\n",
        "        outputs = baseline_model.generate(input_ids=input_ids, max_length=128)\n",
        "        baseline_prediction = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        baseline_preds.append(baseline_prediction)\n",
        "\n",
        "    # Calculate ROUGE for both models\n",
        "    print(\"Calculating ROUGE scores...\")\n",
        "    tuned_results = rouge.compute(\n",
        "        predictions=preds,\n",
        "        references=refs,\n",
        "        use_stemmer=True\n",
        "    )\n",
        "\n",
        "    baseline_results = rouge.compute(\n",
        "        predictions=baseline_preds,\n",
        "        references=refs,\n",
        "        use_stemmer=True\n",
        "    )\n",
        "\n",
        "    # Convert to percentages\n",
        "    tuned_results = {key: value * 100 for key, value in tuned_results.items()}\n",
        "    baseline_results = {key: value * 100 for key, value in baseline_results.items()}\n",
        "\n",
        "    # Display comparison\n",
        "    print(\"\\nComparison with Baseline (untuned) Model:\")\n",
        "    for metric in tuned_results.keys():\n",
        "        if metric in baseline_results:\n",
        "            print(f\"{metric}: Tuned: {tuned_results[metric]:.2f} vs Baseline: {baseline_results[metric]:.2f}\")\n",
        "            print(f\"Improvement: {tuned_results[metric] - baseline_results[metric]:.2f} points\")\n",
        "\n",
        "    return tuned_results, baseline_results\n",
        "\n",
        "# Run the evaluation\n",
        "tuned_results, baseline_results = evaluate_and_compare()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfUFiN1vBzPW",
        "outputId": "c32fada6-7d61-44d6-865b-10b8a17a69cf"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available keys in test_results:\n",
            "- eval_loss\n",
            "- eval_rouge1\n",
            "- eval_rouge2\n",
            "- eval_rougeL\n",
            "- eval_rougeLsum\n",
            "- eval_gen_len\n",
            "- eval_runtime\n",
            "- eval_samples_per_second\n",
            "- eval_steps_per_second\n",
            "- epoch\n",
            "Loading baseline model...\n",
            "Generating predictions...\n",
            "Calculating ROUGE scores...\n",
            "\n",
            "Comparison with Baseline (untuned) Model:\n",
            "rouge1: Tuned: 36.21 vs Baseline: 36.16\n",
            "Improvement: 0.04 points\n",
            "rouge2: Tuned: 9.68 vs Baseline: 7.98\n",
            "Improvement: 1.70 points\n",
            "rougeL: Tuned: 22.34 vs Baseline: 23.98\n",
            "Improvement: -1.65 points\n",
            "rougeLsum: Tuned: 22.41 vs Baseline: 24.09\n",
            "Improvement: -1.68 points\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def visualize_comparison(tuned_results, baseline_results):\n",
        "    # Get common metrics\n",
        "    metrics = [key for key in tuned_results.keys() if key in baseline_results]\n",
        "\n",
        "    tuned_scores = [tuned_results[m] for m in metrics]\n",
        "    baseline_scores = [baseline_results[m] for m in metrics]\n",
        "\n",
        "    x = np.arange(len(metrics))\n",
        "    width = 0.35\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "    baseline_bars = ax.bar(x - width/2, baseline_scores, width, label='Baseline T5')\n",
        "    tuned_bars = ax.bar(x + width/2, tuned_scores, width, label='LoRA Fine-tuned T5')\n",
        "\n",
        "    ax.set_ylabel('Score')\n",
        "    ax.set_title('Metrics: Baseline vs. Fine-tuned Model')\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(metrics)\n",
        "    ax.legend()\n",
        "\n",
        "    # Add value labels on bars\n",
        "    for i, v in enumerate(baseline_scores):\n",
        "        ax.text(i - width/2, v + 0.5, f'{v:.2f}', ha='center')\n",
        "\n",
        "    for i, v in enumerate(tuned_scores):\n",
        "        ax.text(i + width/2, v + 0.5, f'{v:.2f}', ha='center')\n",
        "\n",
        "    fig.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Visualize the results\n",
        "visualize_comparison(tuned_results, baseline_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "evEbt0bfPocp",
        "outputId": "5cb09ba7-932a-48eb-f353-86ad6fe754a0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_technical_report():\n",
        "    # Model parameters\n",
        "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "\n",
        "    # Training details\n",
        "    training_details = {\n",
        "        \"base_model\": \"t5-small\",\n",
        "        \"fine_tuning_method\": \"LoRA (Low-Rank Adaptation)\",\n",
        "        \"training_examples\": len(train_dataset),\n",
        "        \"validation_examples\": len(val_dataset),\n",
        "        \"test_examples\": len(test_dataset),\n",
        "        \"epochs\": training_args.num_train_epochs,\n",
        "        \"learning_rate\": training_args.learning_rate,\n",
        "        \"batch_size\": training_args.per_device_train_batch_size,\n",
        "        \"total_parameters\": total_params,\n",
        "        \"trainable_parameters\": trainable_params,\n",
        "        \"trainable_percentage\": trainable_params / total_params * 100,\n",
        "        \"lora_rank\": 8,  # From your LoRA configuration\n",
        "        \"lora_alpha\": 32,\n",
        "        \"lora_dropout\": 0.1,\n",
        "        \"target_modules\": [\"q\", \"v\"]\n",
        "    }\n",
        "\n",
        "    # Print report\n",
        "    print(\"\\nTechnical Parameters Report:\")\n",
        "    print(\"-\" * 50)\n",
        "    for key, value in training_details.items():\n",
        "        print(f\"{key}: {value}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    return training_details\n",
        "\n",
        "tech_report = generate_technical_report()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyzZ0q5APrw3",
        "outputId": "e1ee6c02-6cb8-4072-c71c-e4f9140faf96"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Technical Parameters Report:\n",
            "--------------------------------------------------\n",
            "base_model: t5-small\n",
            "fine_tuning_method: LoRA (Low-Rank Adaptation)\n",
            "training_examples: 15\n",
            "validation_examples: 5\n",
            "test_examples: 5\n",
            "epochs: 3\n",
            "learning_rate: 0.001\n",
            "batch_size: 2\n",
            "total_parameters: 60801536\n",
            "trainable_parameters: 294912\n",
            "trainable_percentage: 0.48504037792729443\n",
            "lora_rank: 8\n",
            "lora_alpha: 32\n",
            "lora_dropout: 0.1\n",
            "target_modules: ['q', 'v']\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}